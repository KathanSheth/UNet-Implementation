{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of U-Net architecture on Ultrasound Nerve Segmentation Kaggle Challenge\n",
    "\n",
    "## This implementation is based on https://github.com/zhixuhao/unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,concatenate,Conv2D,MaxPooling2D,Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Calculation. Here we use Dice loss as suggested in Competition\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    "smooth = 1.\n",
    "def dice_coff(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](Unet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 96\n",
    "image_width = 96\n",
    "\n",
    "def UNet():\n",
    "    \n",
    "    #Declaring and Designing the Model https://keras.io/getting-started/functional-api-guide/\n",
    "    \n",
    "    inputs = Input((image_height,image_width,1))\n",
    "    \n",
    "    conv_1 = Conv2D(32,(3,3),activation='relu',padding='same')(inputs)\n",
    "    conv_1 = conv2D(32,(3,3),activation='relu',padding='same')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(2,2))(conv_1)\n",
    "    \n",
    "    conv_2 = Conv2D(64,(3,3),activation='relu',padding='same')(pool_1)\n",
    "    conv_2 = conv2D(64,(3,3),activation='relu',padding='same')(conv_2)\n",
    "    pool_2 = MaxPooling2D(pool_size=(2,2))(conv_2)\n",
    "    \n",
    "    conv_3 = Conv2D(128,(3,3),activation='relu',padding='same')(pool_2)\n",
    "    conv_3 = conv2D(128,(3,3),activation='relu',padding='same')(conv_3)\n",
    "    pool_3 = MaxPooling2D(pool_size=(2,2))(conv_3)\n",
    "    \n",
    "    conv_4 = Conv2D(256,(3,3),activation='relu',padding='same')(pool_3)\n",
    "    conv_4 = conv2D(256,(3,3),activation='relu',padding='same')(conv_4)\n",
    "    pool_4 = MaxPooling2D(pool_size=(2,2))(conv_4)\n",
    "    \n",
    "    conv_5 = Conv2D(512,(3,3),activation='relu',padding='same')(pool_4)\n",
    "    conv_5 = conv2D(512,(3,3),activation='relu',padding='same')(conv_5)\n",
    "    \n",
    "    #Here I was little bit confused between Conv2DTranspose or UpSamplin2D with Conv2D\n",
    "    #Explanation is here. \n",
    "    #https://stackoverflow.com/questions/48226783/what-is-the-the-difference-between-performing-upsampling-together-with-strided-t?rq=1\n",
    "    #I am using Conv2DTranspose with kernel size = 2 and stride = 2\n",
    "    \n",
    "    #Concatenation is done on 3rd axis which is channel axis. \n",
    "    up_6 = concatenate([Conv2DTranspose(256,(2,2),strides=(2,2),padding='same')(conv_5),conv_4],axis=3)\n",
    "    conv_6 = Conv2D(256,(3,3),activation='relu',padding='same')(up_6)\n",
    "    conv_6 = Conv2D(256,(3,3),activation='relu',padding='same')(conv_6)\n",
    "    \n",
    "    up_7 = concatenate([Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(conv_6),conv_3],axis=3)\n",
    "    conv_7 = Conv2D(128,(3,3),activation='relu',padding='same')(up_7)\n",
    "    conv_7 = Conv2D(128,(3,3),activation='relu',padding='same')(conv_7)\n",
    "    \n",
    "    up_8 = concatenate([Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(conv_7),conv_2],axis=3)\n",
    "    conv_8 = Conv2D(64,(3,3),activation='relu',padding='same')(up_8)\n",
    "    conv_8 = Conv2D(64,(3,3),activation='relu',padding='same')(conv_8)\n",
    " \n",
    "    up_9 = concatenate([Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(conv_8),conv_1],axis=3)\n",
    "    conv_9 = Conv2D(32,(3,3),activation='relu',padding='same')(up_9)\n",
    "    conv_9 = Conv2D(32,(3,3),activation='relu',padding='same')(conv_9)\n",
    "    \n",
    "    conv_10 = Conv2D(1,(1,1),activation='sigmoid')(conv_9)\n",
    "    \n",
    "    model = Model(inputs=[inputs],outputs=[conv_10])\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=1e-5),loss=dice_coef_loss,metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize images to smaller size\n",
    "def preprocess(images):\n",
    "    images_resized = np.ndarray((images.shape[0],image_height,image_width),dtype=np.uint8)\n",
    "    for i in range(images.shape[0]):\n",
    "        images_resized[i] = resize(images[i],(image_height,image_width),preserve_range=True)\n",
    "        \n",
    "    images_resized = images_resized[...,np.newaxis]\n",
    "    return images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict():\n",
    "    train_images,train_mask_images = data.load_train_data()\n",
    "    \n",
    "    train_images = preprocess(train_images)\n",
    "    train_mask_images = preprocess(train_mask_images)\n",
    "    \n",
    "    train_images = train_images.astype('float32')\n",
    "    mean = np.mean(train_images)\n",
    "    std = np.std(train_images)\n",
    "    \n",
    "    train_images = train_images - mean\n",
    "    train_images = train_images/255.0\n",
    "    \n",
    "    #Importing model\n",
    "    model = UNet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5',monitor='val_loss',save_best_only=True)\n",
    "    \n",
    "    #Fitting the model\n",
    "    model.fit(train_images,train_mask_images,batch_size = 32,nb_epoch=20,verbose=1,shuffle=True,validation_split=0.2,callbacks=[model_checkpoint])\n",
    "    \n",
    "    \n",
    "    test_images,test_id_images = data.load_test_data()\n",
    "    test_images = preprocess(test_images)\n",
    "    \n",
    "    test_images = test_images.astype('float32')\n",
    "    test_images = test_images - mean\n",
    "    test_images = test_images/std\n",
    "    \n",
    "    #Loading Saved weights\n",
    "    model.load_weights('weights.h5')\n",
    "    \n",
    "    #Predicting masks on Test dataset\n",
    "    test_mask_images = model.predict(test_images,verbose=1)\n",
    "    np.save('test_mask.images.npy',test_mask_images)\n",
    "    \n",
    "    #Saving Predicted masks to file\n",
    "    pred_dir = 'predictions'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dic)\n",
    "    for image,image_id in zip(test_mask_images,test_id_images):\n",
    "        image = (image[:,:,0]*255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir,str(image_id) + '_pred.png'),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN THIS ON CPU.\n",
    "##train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
